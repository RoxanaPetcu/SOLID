# SOLID: Self-seeding and Multi-intent Self-instructing LLMs for Generating Intent-aware Information-Seeking dialogs
<img src= "../figures/solid_logov5.png" width=100px></img>
[![](https://img.shields.io/badge/Language-English-brightgreen)](https://github.com/arian-askari/SOLID)

The official repository for the following paper: "SOLID: Self-instructing and Self-seeding LLMs for Large-scale Intent-Aware Informating-Seeeking Dialogue Generation".  **Work in progress: The code is under cleaning/organizing process**

## What we have done?
we propose SOLID to tackle the challenges of using LLMs for generating intent-aware information-seeking dialogues with three novel strategies:

  1. **Self-seeding,** where LLM generates its own dialogue starter seed, ensuring that LLM is familiar with seed;
  2. **Self-instructing,** which involves the LLM to generate its own instructions for significantly reducing the reliance on human-written instructions;
  3. **Intent-aware dialgoues generation**, which automates the dialogue process step by step.
  As an output example of SOLID, we present the SOLID dataset, encompassing more than 300k open-domain, intent-aware dialogues, surpassing the size of existing datasets.
ally generated conversations.
